{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref https://www.kaggle.com/bulentsiyah/mnist-for-beginners-tensorflow-dnn-cnn-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from subprocess import check_output\n",
    "import keras\n",
    "from setuptools.command.setopt import option_base\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import InputLayer\n",
    "from tensorflow.python.keras.layers import MaxPooling2D, MaxPool2D\n",
    "from tensorflow.python.keras.layers import Conv2D, Dense, Flatten,BatchNormalization,Dropout\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.layers.normalization import BatchNormalizationab\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"digit-recognizer/train.csv\")\n",
    "test_orj  = pd.read_csv(\"digit-recognizer/test.csv\")\n",
    "\n",
    "print(\"Training set has {0[0]} rows and {0[1]} columns\".format(train.shape))\n",
    "print(\"Test set has {0[0]} rows and {0[1]} columns\".format(test_orj.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put labels into y_train variable\n",
    "Y_train = train[\"label\"]\n",
    "# Drop 'label' column\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# visualize number of digits classes\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.countplot(Y_train)\n",
    "plt.title(\"Number of digit classes\")\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some samples\n",
    "print(type(X_train))\n",
    "img = X_train.iloc[1].to_numpy()\n",
    "img = img.reshape((28,28))\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.title(train.iloc[0,0])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "test = test_orj.copy() / 255.0\n",
    "\n",
    "# Reshape\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)\n",
    "\n",
    "# Label Encoding \n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "\n",
    "# Split the train and the validation set for the fitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)\n",
    "print(\"x_train shape\",X_train.shape)\n",
    "print(\"x_val shape\",X_val.shape)\n",
    "print(\"y_train shape\",Y_train.shape)\n",
    "print(\"y_test shape\",Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "# Select optimizer\n",
    "sgd = keras.optimizers.SGD(lr=1e-4, momentum=0.9)\n",
    "rms_prop = keras.optimizers.RMSprop(lr=1e-4)\n",
    "adam = keras.optimizers.Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08) \n",
    "adamax = keras.optimizers.Adamax(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "adadelta = keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 86\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),padding='same',activation='relu',input_shape=input_shape))\n",
    "model.add(Conv2D(32,kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,kernel_size=(3, 3),padding='same', activation='relu'))\n",
    "model.add(Conv2D(64,kernel_size=(3, 3),activation='relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy', recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagenn = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagenn.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3 # TODO: 100 -> 3\n",
    "history = model.fit_generator(datagenn.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction],)\n",
    "result = model.evaluate(x=X_train, y=Y_train)\n",
    "print('Accuracy:', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_digits_test=np.argmax(model.predict(test),axis=1)\n",
    "image_id_test=[]\n",
    "for i in range (len(pred_digits_test)):\n",
    "    image_id_test.append(i+1)\n",
    "d={'ImageId':image_id_test,'Label':pred_digits_test}\n",
    "answer=pd.DataFrame(d)\n",
    "answer.to_csv('/tmp/result.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
