{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caffe2.python import workspace\n",
    "from caffe2.python import model_helper\n",
    "from caffe2.python import brew, core\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../digit-recognizer/train.csv')\n",
    "df_test = pd.read_csv('../digit-recognizer/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_np = df.label.values\n",
    "features_np = df.loc[:, df.columns != 'label'].values / 255.0\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(features_np, labels_np, test_size=0.2, random_state=23)\n",
    "\n",
    "X_test = df_test.values / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_db_path = \"/tmp/train.db\"\n",
    "valid_db_path = \"/tmp/valid.db\"\n",
    "test_db_path = \"/tmp/test.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caffe2.proto import caffe2_pb2\n",
    "\n",
    "def create_database(db_name, features, labels=None):\n",
    "    db = core.C.create_db(\"minidb\", db_name, core.C.Mode.new)\n",
    "    tx = db.new_transaction()\n",
    "    for i in range(features.shape[0]):\n",
    "        tensor_protos = caffe2_pb2.TensorProtos()\n",
    "        \n",
    "        feature_proto = tensor_protos.protos.add()\n",
    "        feature_proto.dims.extend(features[i].shape)\n",
    "        feature_proto.data_type = caffe2_pb2.TensorProto.DataType.FLOAT\n",
    "        feature_proto.float_data.extend(features[i].reshape(-1))\n",
    "        \n",
    "        label_proto = tensor_protos.protos.add()\n",
    "        label_proto.data_type = caffe2_pb2.TensorProto.DataType.INT32\n",
    "        label_proto.int32_data.append(labels[i] if labels is not None else -1)\n",
    "        \n",
    "        tx.put('k', tensor_protos.SerializeToString())\n",
    "    del tx\n",
    "    del db\n",
    "\n",
    "create_database(train_db_path, X_train, y_train)\n",
    "create_database(valid_db_path, X_valid, y_valid)\n",
    "create_database(test_db_path, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_input(model, blobs_out, batch_size, db, db_type):\n",
    "    dbreader_name = f\"dbreader_{db}\"\n",
    "    dbreader = model.param_init_net.CreateDB(\n",
    "        [],\n",
    "        dbreader_name,\n",
    "        db=db,\n",
    "        db_type=db_type,\n",
    "    )\n",
    "    return model.net.TensorProtosDBInput(\n",
    "        dbreader, blobs_out, batch_size=batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(name, db_name, batch_size=100, hidden_dim=150, train=True, accuracy=True):\n",
    "    model = model_helper.ModelHelper(name)\n",
    "    \n",
    "    data, label = db_input(\n",
    "        model,\n",
    "        [\"data\", \"label\"],\n",
    "        batch_size=batch_size,\n",
    "        db=db_name,\n",
    "        db_type=\"minidb\",\n",
    "    )\n",
    "    fc1 = brew.fc(model, data, 'fc1', dim_in=28 * 28, dim_out=hidden_dim)\n",
    "    relu1 = model.Relu(fc1, \"relu1\")\n",
    "    \n",
    "    fc2 = brew.fc(model, relu1, \"fc2\", dim_in=hidden_dim, dim_out=hidden_dim)\n",
    "    tanh2 = model.Tanh(fc2, \"tanh2\")\n",
    "    \n",
    "    fc3 = brew.fc(model, tanh2, \"fc3\", dim_in=hidden_dim, dim_out=hidden_dim)\n",
    "    elu3 = model.Elu('fc3', 'elu3')\n",
    "    \n",
    "    fc4 = brew.fc(model, \"elu3\", \"fc4\", dim_in=hidden_dim, dim_out=10)\n",
    "    softmax = model.Softmax(fc4, \"softmax\")\n",
    "    \n",
    "    if train:\n",
    "        xent = model.LabelCrossEntropy([softmax, label], \"xent\")\n",
    "        loss = model.AveragedLoss(xent, \"loss\")\n",
    "        \n",
    "        model.AddGradientOperators([loss])\n",
    "        \n",
    "        LR = model.param_init_net.ConstantFill([], \"LR\", shape=[1], value=-0.02)\n",
    "        ONE = model.param_init_net.ConstantFill([], \"ONE\", shape=[1], value=1.0)\n",
    "        \n",
    "        for param in model.params:\n",
    "            param_grad = model.param_to_grad[param]\n",
    "            model.WeightedSum([param, ONE, param_grad, LR], param)\n",
    "    if accuracy:\n",
    "        model.Accuracy([softmax, label], \"accuracy\")\n",
    "    return model\n",
    "\n",
    "train_model = create_model(\"train_model\", train_db_path, train=True, accuracy=True)\n",
    "valid_model = create_model(\"valid_model\", valid_db_path, train=False, accuracy=True)\n",
    "test_model = create_model(\"test_model\", test_db_path, train=False, accuracy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace.RunNetOnce(test_model.param_init_net)\n",
    "workspace.RunNetOnce(valid_model.param_init_net)\n",
    "workspace.RunNetOnce(train_model.param_init_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_valid_metrics():\n",
    "    workspace.CreateNet(valid_model.net, overwrite=True)\n",
    "    all_accuracy = []\n",
    "    for i in range(X_valid.shape[0] // 100):\n",
    "        workspace.RunNet(valid_model.net.Name())\n",
    "        all_accuracy.append(workspace.FetchBlob(\"accuracy\"))\n",
    "    \n",
    "    return np.array(all_accuracy).mean()\n",
    "\n",
    "workspace.CreateNet(train_model.net, overwrite=True)\n",
    "\n",
    "NUM_EPOCHS = 10000\n",
    "all_train_loss = []\n",
    "all_train_accuracy = []\n",
    "all_valid_accuracy = []\n",
    "for i in range(NUM_EPOCHS):\n",
    "    start_ts = time.time()\n",
    "    workspace.RunNet(train_model.net.Name())\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        train_loss = workspace.FetchBlob(\"loss\")\n",
    "        all_train_loss.append(train_loss)\n",
    "        train_accuracy = workspace.FetchBlob(\"accuracy\")\n",
    "        all_train_accuracy.append(train_accuracy)\n",
    "        valid_accuracy = calc_valid_metrics()\n",
    "        all_valid_accuracy.append(valid_accuracy)\n",
    "        epoch_time = time.time() - start_ts\n",
    "        print(f\"Epoch #{i + 1}/{NUM_EPOCHS}: time elapsed for this epoch {epoch_time}\"\n",
    "              + f\", train_loss {train_loss}, train accuracy {train_accuracy}, valid accuracy {valid_accuracy}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xlist = range(len(all_train_loss))\n",
    "ax.plot(xlist, all_train_loss, label=\"train_loss\")\n",
    "ax.plot(xlist, all_train_accuracy, label=\"train_accuracy\")\n",
    "ax.plot(xlist, all_valid_accuracy, label=\"valid_accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace.CreateNet(test_model.net, overwrite=True)\n",
    "\n",
    "predicted_labels = []\n",
    "for i in range(X_test.shape[0] // 100):\n",
    "    workspace.RunNet(test_model.net.Name())\n",
    "    batch_pred = workspace.FetchBlob(\"softmax\")\n",
    "    if (i + 1) % 20 == 0:\n",
    "        print(f\"Preciction #{i + 1}/{X_test.shape[0] / 100}...\")\n",
    "    for pred in batch_pred:\n",
    "        predicted_labels.append(np.argmax(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(data={\n",
    "    \"ImageId\": range(1, len(predicted_labels) + 1),\n",
    "    \"Label\": predicted_labels\n",
    "})\n",
    "out_df.to_csv(\"/tmp/c2_ref.ans\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
